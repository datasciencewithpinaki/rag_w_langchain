{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d9d7274-8c3f-4ce4-8b4d-a461406dddb6",
   "metadata": {},
   "source": [
    "# Create Agents for LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f5e5dc-2932-4663-b247-f6b7eb2ca067",
   "metadata": {},
   "source": [
    "# Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d940429b-863e-427f-8fc9-d6831125741b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3591966b-ef62-4b30-95af-89c08406800b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2b9a5ee-3ee9-4cdb-a7d1-53a5ec3ce15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from codes.llm_gateway import openAI_wo_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0c2668b-f408-4220-84b3-c80821e5ea48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `AzureChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import AzureChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "llm = openAI_wo_api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902423e0-7f42-4972-a67c-e628d7185ce3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cb0ebb4-16ce-4a8b-be40-f1627971ceaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds two numbers together\"\"\" # this docstring gets used as the description\n",
    "    return a + b # the actions our tool performs\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers together\"\"\" # this docstring gets used as the description\n",
    "    return a * b # the actions our tool performs\n",
    "\n",
    "@tool\n",
    "def power(a: int, b: int) -> int:\n",
    "    \"\"\"Returns 'a' raised to the power 'b'\"\"\" # this docstring gets used as the description\n",
    "    return a**b # the actions our tool performs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "50b637bb-bb5c-4389-b963-014cac0f8e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_date(text:str):\n",
    "    '''\n",
    "    Parses the date given in string to a date format\n",
    "    '''\n",
    "    date_in_ = datetime.date.fromisoformat(text)\n",
    "    return date_in_\n",
    "    \n",
    "@tool\n",
    "def years_between(dob:str, date_on:str=''):\n",
    "    \"\"\"\n",
    "    calculates the difference between the two dates in years\n",
    "    \"\"\"\n",
    "    dob = text_to_date(dob)\n",
    "    date_on = datetime.date.today() if date_on=='' else text_to_date(date_on)\n",
    "    age = (date_on - dob).days\n",
    "    age = round(age / 365, 1)\n",
    "    return age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3fef3e09-071c-45da-8068-0a6043974e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "toolkit = [add, multiply, power, years_between]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "297dae24-6b8a-48d9-a4e7-4cdea852c585",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"\"\"\n",
    "          You are a mathematical assistant. Use your tools to answer questions.\n",
    "          If you do not have a tool to answer the question, say so. \n",
    "        \n",
    "          Return only the answers. e.g\n",
    "          Human: What is 1 + 1?\n",
    "          AI: 2\n",
    "          \"\"\"),\n",
    "        MessagesPlaceholder(\"chat_history\", optional=True),\n",
    "        (\"human\", \"{input}\"),\n",
    "        MessagesPlaceholder(\"agent_scratchpad\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8401bf36-0692-4a43-b558-542b1c97937d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "25250ce6-232f-4c23-856d-78dfe21709ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_openai_tools_agent(llm, toolkit, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8749ff7e-0e10-4134-8708-bd776869d225",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor(agent=agent, tools=toolkit, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab496f94-dd65-4a68-a704-6f1fbb7273e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e73ae029-2ed2-431c-9b24-a5826a6136c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `add` with `{'a': 1, 'b': 1}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m2\u001b[0m\u001b[32;1m\u001b[1;3m2\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result = agent_executor.invoke({\"input\": \"what is 1 + 1\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04667351-84aa-4331-8961-2f4013098f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(result['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "61ecc333-bca4-46d0-8960-7ede9f4dff93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `years_between` with `{'dob': '1986-01-19', 'date_on': '2021-12-15'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m35.9\u001b[0m\u001b[32;1m\u001b[1;3m35\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result = agent_executor.invoke({\"input\": \"I am born on 1986-01-19. What is my age on 2021-12-15?\"})\n",
    "# result = agent_executor.invoke({\"input\": \"I am born on 1986-01-19. What is my age today?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "14fba3f5-35ca-4f41-9de4-8ad15341bb37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    }
   ],
   "source": [
    "print(result['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602e114a-12fd-4a87-a4e6-365626a99f9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f7447a-fba4-465c-9087-4b023a3c787f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69c7982f-2d51-404f-8f4b-d6260f313e99",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Prompt Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a87c2cc-7dc5-4819-ac6f-f6dc9d5a2fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6beb11-1cc0-45d6-9065-330eaa05fba5",
   "metadata": {},
   "source": [
    "### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6e404693-39b4-4648-9a29-c4662bf2b5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "{tools}\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [{tool_names}]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin!\n",
      "\n",
      "Question: {input}\n",
      "Thought:{agent_scratchpad}\n"
     ]
    }
   ],
   "source": [
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "print(prompt.template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628b0263-6720-43b1-b83b-53c4239c9067",
   "metadata": {},
   "source": [
    "### Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "21b9a054-3327-4283-958f-ef65e22be610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['context', 'question'] metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"))]\n"
     ]
    }
   ],
   "source": [
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "49d80f34-ea5f-4843-8052-6d88399e9990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "Question: {question} \n",
      "Context: {context} \n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "type(prompt)\n",
    "print(prompt.messages[0].prompt.template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18feff5-9409-4ddd-b865-ffb9a542f9a1",
   "metadata": {},
   "source": [
    "### Example 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "192c3128-e2e5-4991-a671-2b05eaa2eb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = hub.pull(\"smithing-gold/question-decomposition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "92ef358b-c2e4-4f0b-a085-12e863c9bf94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I’m going to ask you a question. I want you to decompose it into a series of subquestions. Each subquestion should be self-contained with all the information necessary to solve it.\n",
      "\n",
      "Make sure not to decompose more than necessary or have any trivial subquestions - you’ll be evaluated on the simplicity, conciseness, and correctness of your decompositions as well as your final answer. You should wrap each subquestion in <sub q></sub q> tags. After each subquestion, you should answer the subquestion and put your subanswer in <sub a></sub a> tags.\n",
      "\n",
      " Once you have all the information you need to answer the question, output <FIN></FIN> tags.\n",
      "\n",
      "example:\n",
      "Question: What is Bitcoin?\n",
      "<sub q>What is the purpose of Bitcoin?</sub q>\n",
      "<sub a>Bitcoin serves as a decentralized digital currency.</sub a>\n",
      "<sub q>What does decentralized mean?</sub q>\n",
      "<sub a>Decentralized means it operates without a central authority or single administrator.</sub a>\n",
      "<FIN>Bitcoin is a decentralized digital currency that operates without a central authority.</FIN>\n",
      "\n",
      "Question: {question}\n"
     ]
    }
   ],
   "source": [
    "print(prompt.template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f410e37-b663-4476-9c74-197d12a33596",
   "metadata": {},
   "source": [
    "### Exampe 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6c21bc6a-bc38-425a-a652-0efbed07066f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = hub.pull(\"rlm/text-to-sql\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bedb0195-feed-47ef-9ee4-d345a607977e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given an input question, first create a syntactically correct {dialect} query to run, then look at the results of the query and return the answer.\n",
      "Use the following format:\n",
      "\n",
      "Question: \"Question here\"\n",
      "SQLQuery: \"SQL Query to run\"\n",
      "SQLResult: \"Result of the SQLQuery\"\n",
      "Answer: \"Final answer here\"\n",
      "\n",
      "Only use the following tables:\n",
      "\n",
      "{table_info}.\n",
      "\n",
      "Some examples of SQL queries that corrsespond to questions are:\n",
      "\n",
      "{few_shot_examples}\n",
      "\n",
      "Question: {input}\n"
     ]
    }
   ],
   "source": [
    "print(prompt.messages[0].prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d988c2-3ca2-4caa-915a-f8b9013f23cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4647c305-feac-4bb3-9ff4-85cb4a1e024c",
   "metadata": {},
   "source": [
    "## Other Scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "81e29611-2a4a-4b2c-ac0f-d70dc230d3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3c9023e0-fe1c-4dc5-802f-e0dd9dc32971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>position</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>Adam Zohe</td>\n",
       "      <td>pos2</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001</td>\n",
       "      <td>Bevan Young</td>\n",
       "      <td>pos3</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3001</td>\n",
       "      <td>Clarie Xong</td>\n",
       "      <td>pos4</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4001</td>\n",
       "      <td>Daniel Wells</td>\n",
       "      <td>pos3</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5001</td>\n",
       "      <td>Ema Villing</td>\n",
       "      <td>pos3</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id          name position  sales\n",
       "0  1001     Adam Zohe     pos2    100\n",
       "1  2001   Bevan Young     pos3    140\n",
       "2  3001   Clarie Xong     pos4    180\n",
       "3  4001  Daniel Wells     pos3    130\n",
       "4  5001   Ema Villing     pos3    120"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.DataFrame({\n",
    "    'id': [1001, 2001, 3001, 4001, 5001],\n",
    "    'name': ['Adam Zohe', 'Bevan Young', 'Clarie Xong', 'Daniel Wells', 'Ema Villing'],\n",
    "    'position': ['pos2', 'pos3', 'pos4', 'pos3', 'pos3'],\n",
    "    'sales': [100, 140, 180, 130, 120],\n",
    "})\n",
    "\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271e0baa-ba6c-4eb6-a1fb-89eefe6670b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "432edd36-4754-4576-8f49-16cb6b9d5f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent\n",
    "from langchain_experimental.text_splitter import SemanticChunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "612c542d-86d6-471f-bb55-67a22dce8d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_pandas_dataframe_agent(llm, df_test, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3a7252a6-a1f6-41e2-9b4f-ec65d57ecfb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: To find out the size of the dataset, I need to check the number of rows and columns in the dataframe `df`.\n",
      "\n",
      "Action: python_repl_ast\n",
      "Action Input: df.shape\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m(5, 4)\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
      "\n",
      "Final Answer: The dataset contains 5 rows and 4 columns.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "query = \"how big is the dataset?\"\n",
    "result = agent.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9d2215f7-2a49-41a0-80c2-851547736953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains 5 rows and 4 columns.\n"
     ]
    }
   ],
   "source": [
    "print(result['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ab057f3e-63db-4b29-b605-159839c324a4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: To answer this question, I need to group the data by the 'position' column and then calculate the sum or average sales for each position to see if there's a difference.\n",
      "\n",
      "Action: I'll use the groupby() function on the 'position' column and then calculate the mean sales using the mean() function.\n",
      "\n",
      "Action Input: df.groupby('position')['sales'].mean()\u001b[0mI'll use the groupby() function on the 'position' column and then calculate the mean sales using the mean() function. is not a valid tool, try one of [python_repl_ast].\u001b[32;1m\u001b[1;3mI need to use the provided Python shell to execute the command instead of stating what I intend to do. \n",
      "\n",
      "Action: I will use the python_repl_ast to execute the command that will group the dataframe by the 'position' column and calculate the mean sales for each position.\n",
      "\n",
      "Action Input: df.groupby('position')['sales'].mean()\u001b[0mI will use the python_repl_ast to execute the command that will group the dataframe by the 'position' column and calculate the mean sales for each position. is not a valid tool, try one of [python_repl_ast].\u001b[32;1m\u001b[1;3mIt seems I made a mistake in my previous action. I will now correctly use the python_repl_ast tool to execute the command.\n",
      "\n",
      "Action: python_repl_ast\n",
      "Action Input: df.groupby('position')['sales'].mean()\u001b[0m\u001b[36;1m\u001b[1;3mposition\n",
      "pos2    100.0\n",
      "pos3    130.0\n",
      "pos4    180.0\n",
      "Name: sales, dtype: float64\u001b[0m\u001b[32;1m\u001b[1;3mI now know the average sales for each position from the dataframe.\n",
      "\n",
      "Final Answer: Yes, there is a difference in the sales of people from different positions. The average sales for 'pos2' is 100, for 'pos3' is 130, and for 'pos4' is 180.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "query = \"Is there a difference in the sales of people from different positions?\"\n",
    "result = agent.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "12952f9c-206d-44b3-8d6b-a006e9bcc40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, there is a difference in the sales of people from different positions. The average sales for 'pos2' is 100, for 'pos3' is 130, and for 'pos4' is 180.\n"
     ]
    }
   ],
   "source": [
    "print(result['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8985d758-65bb-4a45-8618-be6c0055b1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: To find the average sales per position, I can use the `groupby` function on the 'position' column and then calculate the mean of the 'sales' for each group.\n",
      "\n",
      "Action: python_repl_ast\n",
      "Action Input: import pandas as pd\n",
      "# Assuming df is the DataFrame in question\n",
      "df = pd.DataFrame({\n",
      "    'id': [1001, 2001, 3001, 4001, 5001],\n",
      "    'name': ['Adam Zohe', 'Bevan Young', 'Clarie Xong', 'Daniel Wells', 'Ema Villing'],\n",
      "    'position': ['pos2', 'pos3', 'pos4', 'pos3', 'pos3'],\n",
      "    'sales': [100, 140, 180, 130, 120]\n",
      "})\n",
      "df.groupby('position')['sales'].mean()\u001b[0m\u001b[36;1m\u001b[1;3mposition\n",
      "pos2    100.0\n",
      "pos3    130.0\n",
      "pos4    180.0\n",
      "Name: sales, dtype: float64\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: The average sales from different positions are as follows:\n",
      "- Position pos2: 100.0\n",
      "- Position pos3: 130.0\n",
      "- Position pos4: 180.0\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the average sales from different positions?\"\n",
    "result = agent.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d60e57f9-69ba-4efd-8eff-78179592e191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average sales from different positions are as follows: pos2 has an average sale of 100.0, pos3 has an average sale of 130.0, and pos4 has an average sale of 180.0.\n"
     ]
    }
   ],
   "source": [
    "print(result['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f3c734-487c-447b-9814-0400e896386c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b27375aa-8824-4014-b7f8-fc8c74af931c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Thank you for submitting your request. Hello $contacts.alt_name.first  Thank you for your interest accessing Walmart Luminate Channel Performance>Report Builder. To which Strategic Business Unit (SBU) or Units do you need access? The available SBUs are: •\tApparel •\tConsumables •\tFood •\tGeneral Merchandise •\tHealth and Wellness •\tWalmart Services  It is possible for an associate to get access to ALL SBUs but, to maintain legal compliance, the associate needs to be added to the SEC Insider Trading Blackout List. Adding someone to the Blackout List requires Manager Approval to be documented via email. In case you do need access to ALL SBU's, I am adding <Manager Name in BOLD> to \"Reply all\" to this email and provide an \"I approve\" or \"I do not approve\" response.  We will move forward with creating your account once we have received everyone's response and know which SBU or SBU's to add.  If you wish to access the Shopper Behavior application within Walmart Luminate, please navigate to wmlink/ulearn (https://moodle-azure.prod.walmart.com/moodle/my/) , search for Shopper Behavior, and sign up for a Shopper Behavior: Quick Start course. Access will be granted once the course has been completed.  Customer Perception is used to survey a pool of verified Walmart Customers regarding products and purchase history. Access is restricted to signed Suppliers and select WMT Luminate Support personnel. Internal associate led research projects are managed through the Conversation Ally team. Please review the Best Practices and Qualitative and Quantitative Briefs links below to learn more about submitting a survey request to the Conversation Ally team:  https://one.walmart.com/content/conversation_ally/best-practices.html https://one.walmart.com/content/conversation_ally/quant_qual_briefs.html   Walmart Associates are permissioned to Walmart Luminate by signing up for Shopper Behavior Quick Start in Ulearn. : https://moodle-azure.prod.walmart.com/moodle/mod/facetoface/view.php?id=17168  Associates can also check out wmlink/Walmart-Luminate-for-Merchants to see the Merchandising Resource Center as well.  Once you receive access, you’ll log into the platform at WalmartLuminate.com with Single Sign On (SSO). You will need to be at the office or on VPN.  Thank you, Walmart Luminate Support \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4588723d-001e-4226-a0eb-76f0b1847700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thank you for submitting your request. Hello $contacts.alt_name.first  Thank you for your interest accessing Walmart Luminate Channel Performance>Report Builder. To which Strategic Business Unit (SBU) or Units do you need access? The available SBUs are: •\tApparel •\tConsumables •\tFood •\tGeneral Merchandise •\tHealth and Wellness •\tWalmart Services  It is possible for an associate to get access to ALL SBUs but, to maintain legal compliance, the associate needs to be added to the SEC Insider Trading Blackout List. Adding someone to the Blackout List requires Manager Approval to be documented via email. In case you do need access to ALL SBU's, I am adding <Manager Name in BOLD> to \"Reply all\" to this email and provide an \"I approve\" or \"I do not approve\" response.  We will move forward with creating your account once we have received everyone's response and know which SBU or SBU's to add.  If you wish to access the Shopper Behavior application within Walmart Luminate, please navigate to wmlink/ulearn (https://moodle-azure.prod.walmart.com/moodle/my/) , search for Shopper Behavior, and sign up for a Shopper Behavior: Quick Start course. Access will be granted once the course has been completed.  Customer Perception is used to survey a pool of verified Walmart Customers regarding products and purchase history. Access is restricted to signed Suppliers and select WMT Luminate Support personnel. Internal associate led research projects are managed through the Conversation Ally team. Please review the Best Practices and Qualitative and Quantitative Briefs links below to learn more about submitting a survey request to the Conversation Ally team:  https://one.walmart.com/content/conversation_ally/best-practices.html https://one.walmart.com/content/conversation_ally/quant_qual_briefs.html   Walmart Associates are permissioned to Walmart Luminate by signing up for Shopper Behavior Quick Start in Ulearn. : https://moodle-azure.prod.walmart.com/moodle/mod/facetoface/view.php?id=17168  Associates can also check out wmlink/Walmart-Luminate-for-Merchants to see the Merchandising Resource Center as well.  Once you receive access, you’ll log into the platform at WalmartLuminate.com with Single Sign On (SSO). You will need to be at the office or on VPN.  Thank you, Walmart Luminate Support \n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fde15e5-8fe4-4474-8b70-1a93b1165d8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1baa974-4945-4ea2-9a81-ac24c22448d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
